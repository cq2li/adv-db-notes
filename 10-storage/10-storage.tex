\documentclass[11pt]{article}

\newcommand{\lecturenumber}{10}
\newcommand{\lecturename}{Storage Models and Data Layout}
\newcommand{\lecturedata}{2018-02-19}

\usepackage{../dbnotes}

\begin{document}

\maketitle
\thispagestyle{plain}

%% ==================================================================
%% DATA ORGANIZATION
%% ==================================================================
\section{Data Organization}
One can think of an in-memory database as a large array of bytes.
The schema tells the DBMS how to convert the bytes into the appropriate type.
Each tuple is prefixed with a header that contains its meta-data.

Store tuples with fixed-length data makes it easy to compute the starting point of any tuple.
Mapping virtual memory pages to database pages.

%% ----------------------------------------------------
%% Memory Pages
%% ----------------------------------------------------
\subsection*{Memory Pages}
\begin{itemize}
    \item
    The OS maps physical pages to virtual memory pages.
    
    \item
    The CPU's \textit{memory management unit} (MMU) maintains a \textit{translation lookaside 
    buffer} (TLB) that contains the physical address of a virtual memory page.
\end{itemize}

%% ----------------------------------------------------
%% Transparent Huge Pages
%% ----------------------------------------------------
\subsection*{Transparent Huge Pages}
One potential optimization for an in-memory DBMS is to use ``huge'' memory pages. The default page 
size is 4KB. Using larger pages means that it takes fewer TLB entries to map to a larger amount of 
memory.

Linux supports a \textit{transparent huge pages} optimization that allows applications to 
automatically take advantage of huge pages.
\begin{itemize}
    \item
    All pages are automatically set to either 2MB or 1GB (depending on what the CPU supports).
    
    \item
    Each page has to be a contiguous block of memory. The OS can fall-back to the default 4KB page 
if     a large segment of memory is not available.
\end{itemize}

Most DBMSs tell you to disable huge pages because they can stall processes that attempt to access 
a memory page while the OS is reorganizing layout.

%% ==================================================================
%% DATA REPRESENTATION
%% ==================================================================
\section{Data Representation}
This determines how a DBMS stores the actual bits for a value in-memory.

All integers are stored in their ``native'' C/C++ as specified by the IEEE-754 
standard~\cite{ieee754}.

%% ----------------------------------------------------
%% Variable Precision Numbers
%% ----------------------------------------------------
\subsection*{Variable Precision Numbers}
\begin{itemize}
    \item
    Inexact, variable-precision numeric type that uses the ``native'' C/C++ types specified by 
    IEEE-754 standard.
    
    \item
    Faster than arbitrary precision numbers because the CPU can execute instructions on them 
    directly.
    
    \item
    Example: \sql{FLOAT}, \sql{REAL}
\end{itemize}

%% ----------------------------------------------------
%% Fixed Point Precision Numbers
%% ----------------------------------------------------
\subsection*{Fixed Point Precision Numbers}
\begin{itemize}
    \item
    Numeric data types with arbitrary precision and scale.
    Typically stored in exact, variable-length binary representation with additional meta-data.
    
    \item
    Used when rounding errors are unacceptable.
    
    \item Example: \sql{NUMERIC}, \sql{DECIMAL}
\end{itemize}

%% ----------------------------------------------------
%% NULL Data Types
%% ----------------------------------------------------
\subsection*{NULL Data Types}

\textbf{Approach \#1 -- Special Values:}
\begin{itemize}
    \item
    Designate a value to represent \sql{NULL} for a particular 
    data type (e.g., \texttt{INT32\_MIN}).
    
    \item
    DBMS needs to make sure that the application does not try to insert a tuple with that value.
\end{itemize}

\textbf{Approach \#2 -- Null Column Bitmap:} 
\begin{itemize}
    \item
    Store a bitmap in the header of every tuple that specifies 
    which of its attributes are \sql{NULL}.
    
    \item
    The length of the bitmap is usually the number of attributes in the tuple (even if those 
    attributes are not null-able).
    
    \item
    This is the most widely used approach in both disk-oriented and in-memory DBMSs.
\end{itemize}

\textbf{Approach \#3 -- Per Attribute Flag:}
\begin{itemize}
    \item
    Store a prefix in-memory for an attribute that represents whether that value is \sql{NULL}. 

    \item
    Although the flag only needs to be a single bit (i.e., true/false), this approach has to 
    use more space than just a single bit because this messes with word alignment.
    For example, if the CPU fetches a value that is not word-aligned, it has to do 
    extra work to provide the application with the correct value:
    \begin{itemize}
        \item
        Execute two reads to load the appropriate parts of the data word and reassemble them.
        This is the approach used in all Intel CPUs and newer ARM CPUs.
        
        \item
        Read some unexpected combination of bytes assembled into a single word.
        
        \item
        Throw an exception.
    \end{itemize}
    
    \item
    Only used by MemSQL.
\end{itemize}

%% ==================================================================
%% STORAGE MODELS
%% ==================================================================
\section{Storage Models}

%% ----------------------------------------------------
%% N-Ary Storage Model
%% ----------------------------------------------------
\subsection*{N-Ary Storage Model (NSM)}
The DBMS stores all of the attributes for a single tuple contiguously.
Also known as a ``row store''.
This approach is ideal for OLTP workloads where transactions tend to operate only an individual 
entity and insert heavy workloads.

\textbf{Advantages:}
\begin{itemize}
    \item
    Fast inserts, updates, and deletes.
    
    \item
    Good for queries that need the entire tuple.
\end{itemize}

\textbf{Disadvantages:}
\begin{itemize}
    \item
    Not good for scanning large portions of the table and/or a subset of the attributes.
    This is because it pollutes the CPU cache by fetching data that is not needed for processing
    the query.
\end{itemize}

There are two different ways to organize a NSM database:
\begin{itemize}
    \item \textbf{Heap Organized Tables:}
    Tuples are stored in blocks called a heap, and the heap does not necessarily define an order.
    
    \item \textbf{Index-Organized Tables:}
    Tuples are stored in the primary key index itself, but different from a clustered index.
\end{itemize}
    
%% ----------------------------------------------------
%% Decomposition Storage Model
%% ----------------------------------------------------
\subsection*{Decomposition Storage Model (DSM)}
The DBMS stores a single attribute for all tuples contiguously in a block of data. Also known as a 
``column store''. This model is ideal for OLAP workloads where read-only queries perform large scans 
over a subset of the table's attributes. The DBMS is also able to use the vector-at-a-time iterator 
model.

\textbf{Advantages:}
\begin{itemize}
    \item
    Reduces the amount of wasted work during query execution because the DBMS only reads the data 
    that it needs for that query.
    
    \item
    Enables better compression because all of the values for the same attribute are store 
    contiguously in a single column.
\end{itemize}

\textbf{Disadvantages:}
\begin{itemize}
    \item
    Slow for point queries, inserts, updates, and deletes because of tuple 
    splitting/stitching.
\end{itemize}

%% ==================================================================
%% HYBRID STORAGE MODELS
%% ==================================================================
\section{Hybrid Storage Models}
Single logical database instance that uses different storage models for hot and cold 
data. Data is ``hot'' when first entered into the database, as it is more likely to updated 
again near the future. Thus, the DBMS can store new data in NSM for fast OLTP operations. It then 
migrates data to DSM as it ages for more efficient OLAP.

Approaches for Categorizing Data:
\begin{itemize}
    \item \textbf{Manual:}
    DBA specifies what tables should be stored in DSM.
    
    \item \textbf{Off-Line:}
    DBMS monitors access logs off-line and them makes decisions about what 
    data to move to DSM.
    
    \item \textbf{On-Line:}
    DBMS tracks access patterns at runtime and then makes decision about what data to move to DSM.
\end{itemize}

%% ----------------------------------------------------
%% Decomposition Storage Model
%% ----------------------------------------------------
\subsection*{Approach \#1 -- Separate Execution Engine:}
Run separate ``internal'' DBMSs that each only operate on DSM or NSM data.
The system will combine of query results from both engines to appear as a single 
logical database to the application.
This requires a synchronization method (e.g., two-phase commit) if a transaction spans execution 
engines.

\textbf{Fractured Mirrors:}~\cite{p430-ramamurthy}
\begin{itemize}
    \item
    Store a second copy of the database in a DSM layout that is automatically updated.
    
    \item
    All updates are first entered in NSM then eventually copied into DSM mirror.
    
    \item
    Examples: \dbSys{Oracle In-Memory Column Store}, \dbSys{IBM DB2 BLU}.
\end{itemize}

\textbf{Delta Store:}
\begin{itemize}
    \item
    Stage updates to the database in an NSM table.
    
    \item
    A background thread migrates updates from delta store and applies them to DSM data.
    
    \item
    Examples: \dbSys{SAP HANA}, \dbSys{MemSQL}, \dbSys{Vertica}
\end{itemize}

%% ----------------------------------------------------
%% Decomposition Storage Model
%% ----------------------------------------------------
\subsection{Approach \#2 -- Adaptive Storage}
The DBMS uses single execution engine that is able to operate on both NSM and DSM 
data~\cite{p583-arulraj}.

\begin{itemize}
    \item
    No need to store two copies of the database.
    
    \item
    No need to sync multiple database segments.
    
    \item
    Note that a DBMS can still use a delta-store approach with this single-engine architecture.
\end{itemize}

% ==================================================================
% BIBLIOGRAPHY
% ==================================================================
\newpage
\bibliographystyle{abbrvnat}
\bibliography{10-storage}

\end{document}
