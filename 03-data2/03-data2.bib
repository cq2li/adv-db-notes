@book{ieee754,
    title={{IEEE standard for binary floating-point arithmetic}},
    booktitle={{IEEE standard for binary floating-point arithmetic}},
    publisher={Institute of Electrical and Electronics Engineers},
    address={New York},
    year={1985},
}


@inproceedings{p430-ramamurthy,
  author = {Ramamurthy, Ravishankar and
            DeWitt, David J. and
            Su, Qi},
  title = {A case for fractured mirrors},
  booktitle = {VLDB '02 Proceedings of the 28th international conference on Very Large Data Bases},
  month = {August},
  year = {2002},
  pages = {430--441},
  doi = {https://dl.acm.org/citation.cfm?id=1287407},
}

@inproceedings{p583-arulraj,
  author = {Arulraj, Joy and
            Pavlo, Andrew and
            Menon, Prashanth},
  title = {Bridging the Archipelago between Row-Stores and Column-Stores for Hybrid Workloads},
  booktitle = {SIGMOD '16 Proceedings of the 2016 International Conference on Management of Data},
  month = {June},
  year = {2016},
  pages = {583--598},
  doi = {https://dl.acm.org/citation.cfm?id=2915231},
}

@inproceedings{Abadi,
 author = {Abadi, Daniel J. and Madden, Samuel R. and Hachem, Nabil},
 title = {Column-stores vs. Row-stores: How Different Are They Really?},
 booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '08},
 year = {2008},
 location = {Vancouver, Canada},
 pages = {967--980},
 numpages = {14},
 acmid = {1376712},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{btrblocks,
author = {Kuschewski, Maximilian and Sauerwein, David and Alhomssi, Adnan and Leis, Viktor},
title = {BtrBlocks: Efficient Columnar Compression for Data Lakes},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {2},
url = {https://doi.org/10.1145/3589263},
doi = {10.1145/3589263},
abstract = {Analytics is moving to the cloud and data is moving into data lakes. These reside on object storage services like S3 and enable seamless data sharing and system interoperability. To support this, many systems build on open storage formats like Apache Parquet. However, these formats are not optimized for remotely-accessed data lakes and today's high-throughput networks. Inefficient decompression makes scans CPU-bound and thus increases query time and cost. With this work we present BtrBlocks, an open columnar storage format designed for data lakes. BtrBlocks uses a set of lightweight encoding schemes, achieving fast and efficient decompression and high compression ratios.},
journal = {Proc. ACM Manag. Data},
month = {jun},
articleno = {118},
numpages = {26},
keywords = {columnar storage, compression, data lake, query processing}
}

@article{fastlanes,
author = {Afroozeh, Azim and Boncz, Peter},
title = {The FastLanes Compression Layout: Decoding $>$ 100 Billion Integers per Second with Scalar Code},
year = {2023},
issue_date = {May 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {9},
issn = {2150-8097},
url = {https://doi.org/10.14778/3598581.3598587},
doi = {10.14778/3598581.3598587},
abstract = {The open-source FastLanes project aims to improve big data formats, such as Parquet, ORC and columnar database formats, in multiple ways. In this paper, we significantly accelerate decoding of all common Light-Weight Compression (LWC) schemes: DICT, FOR, DELTA and RLE through better data-parallelism. We do so by re-designing the compression layout using two main ideas: (i) generalizing the value interleaving technique in the basic operation of bit-(un)packing by targeting a virtual 1024-bits SIMD register, (ii) reordering the tuples in all columns of a table in the same Unified Transposed Layout that puts tuple chunks in a common "04261537" order (explained in the paper); allowing for maximum independent work for all possible basic SIMD lane widths: 8, 16, 32, and 64 bits.We address the software development, maintenance and future-proofness challenges of increasing hardware diversity, by defining a virtual 1024-bits instruction set that consists of simple operators supported by all SIMD dialects; and also, importantly, by scalar code. The interleaved and tuple-reordered layout actually makes scalar decoding faster, extracting more data-parallelism from today's wide-issue CPUs. Importantly, the scalar version can be fully auto-vectorized by modern compilers, eliminating technical debt in software caused by platform-specific SIMD intrinsics.Micro-benchmarks on Intel, AMD, Apple and AWS CPUs show that FastLanes accelerates decoding by factors (decoding >40 values per CPU cycle). FastLanes can make queries faster, as compressing the data reduces bandwidth needs, while decoding is almost free.},
journal = {Proc. VLDB Endow.},
month = {may},
pages = {2132–2144},
numpages = {13}
}

@inproceedings{bitweaving,
author = {Li, Yinan and Patel, Jignesh M.},
title = {BitWeaving: fast scans for main memory data processing},
year = {2013},
isbn = {9781450320375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2463676.2465322},
doi = {10.1145/2463676.2465322},
abstract = {This paper focuses on running scans in a main memory data processing system at "bare metal" speed. Essentially, this means that the system must aim to process data at or near the speed of the processor (the fastest component in most system configurations). Scans are common in main memory data processing environments, and with the state-of-the-art techniques it still takes many cycles per input tuple to apply simple predicates on a single column of a table. In this paper, we propose a technique called BitWeaving that exploits the parallelism available at the bit level in modern processors. BitWeaving operates on multiple bits of data in a single cycle, processing bits from different columns in each cycle. Thus, bits from a batch of tuples are processed in each cycle, allowing BitWeaving to drop the cycles per column to below one in some case. BitWeaving comes in two flavors: BitWeaving/V which looks like a columnar organization but at the bit level, and BitWeaving/H which packs bits horizontally. In this paper we also develop the arithmetic framework that is needed to evaluate predicates using these BitWeaving organizations. Our experimental results show that both these methods produce significant performance benefits over the existing state-of-the-art methods, and in some cases produce over an order of magnitude in performance improvement.},
booktitle = {Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data},
pages = {289–300},
numpages = {12},
keywords = {analytics, bit-parallel, indexing, intra-cycle parallelism, storage organization},
location = {New York, New York, USA},
series = {SIGMOD '13}
}

@article{simdfastscan,
author = {Willhalm, Thomas and Popovici, Nicolae and Boshmaf, Yazan and Plattner, Hasso and Zeier, Alexander and Schaffner, Jan},
title = {SIMD-scan: ultra fast in-memory table scan using on-chip vector processing units},
year = {2009},
issue_date = {August 2009},
publisher = {VLDB Endowment},
volume = {2},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/1687627.1687671},
doi = {10.14778/1687627.1687671},
abstract = {The availability of huge system memory, even on standard servers, generated a lot of interest in main memory database engines. In data warehouse systems, highly compressed column-oriented data structures are quite prominent. In order to scale with the data volume and the system load, many of these systems are highly distributed with a shared-nothing approach. The fundamental principle of all systems is a full table scan over one or multiple compressed columns. Recent research proposed different techniques to speedup table scans like intelligent compression or using an additional hardware such as graphic cards or FPGAs. In this paper, we show that utilizing the embedded Vector Processing Units (VPUs) found in standard superscalar processors can speed up the performance of mainmemory full table scan by factors. This is achieved without changing the hardware architecture and thereby without additional power consumption. Moreover, as on-chip VPUs directly access the system's RAM, no additional costly copy operations are needed for using the new SIMD-scan approach in standard main memory database engines. Therefore, we propose this scan approach to be used as the standard scan operator for compressed column-oriented main memory storage. We then discuss how well our solution scales with the number of processor cores; consequently, to what degree it can be applied in multi-threaded environments. To verify the feasibility of our approach, we implemented the proposed techniques on a modern Intel multi-core processor using Intel® Streaming SIMD Extensions (Intel® SSE). In addition, we integrated the new SIMD-scan approach into SAP® Netweaver® Business Warehouse Accelerator. We conclude with describing the performance benefits of using our approach for processing and scanning compressed data using VPUs in column-oriented main memory database systems.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {385–394},
numpages = {10}
}

@article{quickstep,
author = {Patel, Jignesh M. and Deshmukh, Harshad and Zhu, Jianqiao and Potti, Navneet and Zhang, Zuyu and Spehlmann, Marc and Memisoglu, Hakan and Saurabh, Saket},
title = {Quickstep: a data platform based on the scaling-up approach},
year = {2018},
issue_date = {February 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {6},
issn = {2150-8097},
url = {https://doi.org/10.14778/3184470.3184471},
doi = {10.14778/3184470.3184471},
abstract = {Modern servers pack enough storage and computing power that just a decade ago was spread across a modest-sized cluster. This paper presents a prototype system, called Quickstep, to exploit the large amount of parallelism that is packed inside modern servers. Quickstep builds on a vast body of previous methods for organizing data, optimizing, scheduling and executing queries, and brings them together in a single system. Quickstep also includes new query processing methods that go beyond previous approaches. To keep the project focused, the project's initial target is read-mostly in-memory data warehousing workloads in single-node settings. In this paper, we describe the design and implementation of Quickstep for this target application space. We also present experimental results comparing the performance of Quickstep to a number of other systems, demonstrating that Quickstep is often faster than many other contemporary systems, and in some cases faster by orders-of-magnitude. Quickstep is an Apache (incubating) project.},
journal = {Proc. VLDB Endow.},
month = {feb},
pages = {663–676},
numpages = {14}
}

@article{varindexes,
author = {O'Neil, Patrick and Quass, Dallan},
title = {Improved query performance with variant indexes},
year = {1997},
issue_date = {June 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/253262.253268},
doi = {10.1145/253262.253268},
abstract = {The read-mostly environment of data warehousing makes it possible to use more complex indexes to speed up queries than in situations where concurrent updates are present. The current paper presents a short review of current indexing technology, including row-set representation by Bitmaps, and then introduces two approaches we call Bit-Sliced indexing and Projection indexing. A Projection index materializes all values of a column in RID order, and a Bit-Sliced index essentially takes an orthogonal bit-by-bit view of the same data. While some of these concepts started with the MODEL 204 product, and both Bit-Sliced and Projection indexing are now fully realized in Sybase IQ, this is the first rigorous examination of such indexing capabilities in the literature. We compare algorithms that become feasible with these variant index types against algorithms using more conventional indexes. The analysis demonstrates important performance advantages for variant indexes in some types of SQL aggregation, predicate evaluation, and grouping. The paper concludes by introducing a new method whereby multi-dimensional group-by queries, reminiscent of OLAP/Datacube queries but with more flexibility, can be very efficiently performed.},
journal = {SIGMOD Rec.},
month = {jun},
pages = {38–49},
numpages = {12}
}

@article{Chambi_2015,
   title={Better bitmap performance with Roaring bitmaps},
   volume={46},
   ISSN={1097-024X},
   url={http://dx.doi.org/10.1002/spe.2325},
   DOI={10.1002/spe.2325},
   number={5},
   journal={Software: Practice and Experience},
   publisher={Wiley},
   author={Chambi, Samy and Lemire, Daniel and Kaser, Owen and Godin, Robert},
   year={2015},
   month=apr, pages={709–719} }

@article{fsst,
author = {Boncz, Peter and Neumann, Thomas and Leis, Viktor},
title = {FSST: fast random access string compression},
year = {2020},
issue_date = {August 2020},
publisher = {VLDB Endowment},
volume = {13},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3407790.3407851},
doi = {10.14778/3407790.3407851},
abstract = {Strings are prevalent in real-world data sets. They often occupy a large fraction of the data and are slow to process. In this work, we present Fast Static Symbol Table (FSST), a lightweight compression scheme for strings. On text data, FSST offers decompression and compression speed similar to or better than the best speed-optimized compression methods, such as LZ4, yet offers significantly better compression factors. Moreover, its use of a static symbol table allows random access to individual, compressed strings, enabling lazy decompression and query processing on compressed data. We believe these features will make FSST a valuable piece in the standard compression toolbox.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {2649–2661},
numpages = {13}
}

@article{freq-encoding,
author = {Raman, Vijayshankar and Attaluri, Gopi and Barber, Ronald and Chainani, Naresh and Kalmuk, David and KulandaiSamy, Vincent and Leenstra, Jens and Lightstone, Sam and Liu, Shaorong and Lohman, Guy M. and Malkemus, Tim and Mueller, Rene and Pandis, Ippokratis and Schiefer, Berni and Sharpe, David and Sidle, Richard and Storm, Adam and Zhang, Liping},
title = {DB2 with BLU acceleration: so much more than just a column store},
year = {2013},
issue_date = {August 2013},
publisher = {VLDB Endowment},
volume = {6},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/2536222.2536233},
doi = {10.14778/2536222.2536233},
abstract = {DB2 with BLU Acceleration deeply integrates innovative new techniques for defining and processing column-organized tables that speed read-mostly Business Intelligence queries by 10 to 50 times and improve compression by 3 to 10 times, compared to traditional row-organized tables, without the complexity of defining indexes or materialized views on those tables. But DB2 BLU is much more than just a column store. Exploiting frequency-based dictionary compression and main-memory query processing technology from the Blink project at IBM Research - Almaden, DB2 BLU performs most SQL operations - predicate application (even range predicates and IN-lists), joins, and grouping - on the compressed values, which can be packed bit-aligned so densely that multiple values fit in a register and can be processed simultaneously via SIMD (single-instruction, multipledata) instructions. Designed and built from the ground up to exploit modern multi-core processors, DB2 BLU's hardware-conscious algorithms are carefully engineered to maximize parallelism by using novel data structures that need little latching, and to minimize data-cache and instruction-cache misses. Though DB2 BLU is optimized for in-memory processing, database size is not limited by the size of main memory. Fine-grained synopses, late materialization, and a new probabilistic buffer pool protocol for scans minimize disk I/Os, while aggressive prefetching reduces I/O stalls. Full integration with DB2 ensures that DB2 with BLU Acceleration benefits from the full functionality and robust utilities of a mature product, while still enjoying order-of-magnitude performance gains from revolutionary technology without even having to change the SQL, and can mix column-organized and row-organized tables in the same tablespace and even within the same query.},
journal = {Proc. VLDB Endow.},
month = {aug},
pages = {1080–1091},
numpages = {12}
}


@article{rel-model,
author = {Codd, E. F.},
title = {A relational model of data for large shared data banks},
year = {1970},
issue_date = {June 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/362384.362685},
doi = {10.1145/362384.362685},
abstract = {Future users of large data banks must be protected from having to know how the data is organized in the machine (the internal representation). A prompting service which supplies such information is not a satisfactory solution. Activities of users at terminals and most application programs should remain unaffected when the internal representation of data is changed and even when some aspects of the external representation are changed. Changes in data representation will often be needed as a result of changes in query, update, and report traffic and natural growth in the types of stored information.Existing noninferential, formatted data systems provide users with tree-structured files or slightly more general network models of the data. In Section 1, inadequacies of these models are discussed. A model based on n-ary relations, a normal form for data base relations, and the concept of a universal data sublanguage are introduced. In Section 2, certain operations on relations (other than logical inference) are discussed and applied to the problems of redundancy and consistency in the user's model.},
journal = {Commun. ACM},
month = {jun},
pages = {377–387},
numpages = {11},
keywords = {composition, consistency, data bank, data base, data integrity, data organization, data structure, derivability, hierarchies of data, join, networks of data, predicate calculus, redundancy, relations, retrieval language, security}
}
