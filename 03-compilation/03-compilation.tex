\documentclass[11pt]{article}

\newcommand{\lecturenumber}{3}
\newcommand{\lecturename}{Query Compilation}
\newcommand{\lecturedata}{2018-01-24}

\usepackage{../dbnotes}

\begin{document}

\maketitle
\thispagestyle{plain}

\section{Background}
\begin{itemize}
    \item After switching to an in-memory DBMS, the only ways to increase throughput is to reduce the number of instructions executed
        \begin{itemize}
            \item To go 10x faster, the DBMS must execute 90\% fewer instructions
            \item To go 100x faster, the DBMS must execute 99\% fewer instructions
        \end{itemize}
    \item One way to achieve such a reduction is through code specialization. This means generating code that is specific to a particular task in the DBMS (e.g. a specific query)
\end{itemize}


\section{Query Processing}
\begin{itemize}
    \item \textbf{Tuple-at-a-time}: Each operator calls \textbf{next} on their child to get the next tuple to process
    \item \textbf{Operator-at-a-time}: Each operator materializes their entire output for their parent operator
    \item \textbf{Vector-at-a-time}: Each operator calls \textbf{next} on their child to get the next \textbf{batch} of data to process
    \item Predicate interpretation
    \begin{itemize}
        \item DBMS evaluates predicates using an expression tree
        \item Expression trees are very expensive with a lot of tuples
    \end{itemize}
\end{itemize}

\section{Code Specialization}
\begin{itemize}
    \item Any CPU intensive entity of database can be natively compiled if they have a similar execution pattern on different inputs
    \begin{itemize}
        \item Access methods
        \item Stored procedure
        \item Operator execution
        \item Predicate evaluation
        \item Logging operations
    \end{itemize}
    \item Benefits of Code Specialization
    \begin{itemize}
        \item Attribute types are knwon a priori: Data access function calls can be converted to inline pointer casting
        \item Predicates are known a priori: They can be evaluated using primitive data comparisons
        \item No function calls in loops: Allows the compiler to efficiently distribute data to registers and increase cache reuse
        \item All possible because RDBMSs have schemas
    \end{itemize}
\end{itemize}

\section{Code Generation}
\begin{itemize}
    \item Approach 1 - Transpilation: Write code that converts a relational query plan into C/C++ and then run it through a conventional compiler to generate native code
    \begin{itemize}
        \item For a given query plan, generate a C/C++ program that implements that query's execution
        \item Use an off-shelf compiler to convert the code into a shared object, link it to the DBMS process, and invoke the exec function
        \item The generated query code can invoke any other function in the DMBS
        \item This allows it to use all the same components as interpreted queries (e.g. concurrency control, logging/checkpoints)
        \item Evaluation observations
        \begin{itemize}
            \item Very little memory stall
            \item Increased instruction execution
            \item Compilation time is very long
        \end{itemize}
    \end{itemize}
    \item Approach 2 - JIT Compilation: Generate an intermediate representation (IR) of the query that can be quickly compiled into native code
    \begin{itemize}
        \item Pipeline boundaries: edge of where a tuple can reach in the pipeline before needing the next tuple becomes necessary
        \item Compile queries in-memory into native code using the LLVM toolkit
        \item Organizes query processing in a way to keep a tuple in CPU registers for as long as possible
        \begin{itemize}
            \item Push based vs Pull-based
            \item Data Centric vs Operator Centric
        \end{itemize}
        \item \textbf{LLVM}
        \begin{itemize}
            \item Collection of modular and reusable compiler and toolchain technologies
            \item Core component is a low-level programming language (IR) that is similar to assembly
            \item Not all of the DBMS components need to be written in LLVM IR. The LLVM code can make calls to C++ code
        \end{itemize}
        \item Query compilation cost
        \begin{itemize}
            \item LLVM compilation time grows super-linearly relative to the query size (# of joins, predicates, and aggregations)
            \item Not a big issues with OLTP applications
            \item Major problem with OLAP workloads
            \item \textbf{Solution: Hyper - Adaptive Execution}
            \begin{enumerate}
                \item First generate the LLVM IR for the query
                \item Execute the IR in an interpreter
                \item Compiler the query in the background
                \item When the compiled query is ready, seamlesly replace the interpretive execution
            \end{enumerate}
        \end{itemize}
    \end{itemize}
\end{itemize}

\section{Real World Implementations}
\begin{itemize}
    \item IBM System R
    \begin{itemize}
        \item A primitive form of code generation and query compilation was used by IBM in 1970s
        \item Compiled SQL statements into assembly code by selecting code templates for each operator
        \item Technique was abandoned when IBM built DB2
    \end{itemize}
    \item Oracle
    \begin{itemize}
        \item Convert PL/SQL stored procedures into Pro*C code and then compiled into native C/C++ code
        \item They also put Oracle-specific operations directly in the SPARC chips as co-processors
    \end{itemize}
    \item Microsoft Hekaton
    \begin{itemize}
        \item Can compile both procedures and SQL
        \item Non-Hekaton queries can access Hekaton tables through compiled inter-operators
        \item Generates C code from an imperative syntax tree, compiles it into DDL, and links at runtime
    \end{itemize}
    \item Cloudera Impala
    \begin{itemize}
        \item LLVM JIT compilation for predicate evaluation and record parsing
        \item Not sure if they are also doing operator compilation
        \item Optimized record parsing is important for Impala because they need to handle multiple data formats stored on HDFS
    \end{itemize}
    \item Actian Vector (former VectorWise)
    \begin{itemize}
        \item Pre-compile thousands of "primitives" that perform basic operations on typed data
        \item The DBMS then executes a query plan that invokes these primitives at runtime
    \end{itemize}
    \item MemSQL (Pre-2016)
    \begin{itemize}
        \item Performs the same C/C++ code generation as HIQUE and then invokes gcc
        \item Converts all queries into a parameterized form and caches the compiled query plan
    \end{itemize}
    \item MemSQL (2016 - Present)
    \begin{itemize}
        \item A query plan is converted into an imperative plan expressed in a high-level imperative DSL
        \item MemSQL Programming Language (MLP), think of it like a C++ dialect
        \item The DSL then gets executed into a second language of opcodes
        \item Finally the DBMS compiles the opcodes into LLVM IR and then to native code
    \end{itemize}
    \item VitesseDB
    \begin{itemize}
        \item Query accelerator for Postgres/Greenplum that uses LLVM + intra-query parallelism
        \item JIT Predicates
    \end{itemize}
    \item Apache Spark
    \begin{itemize}
        \item Introduced in the new Tungsten engine in 2015
        \item The system converts a query's WHERE clause expression trees into AST
        \item It then compiles these ASTs to generate JVM bytecode, which is then executed natively
    \end{itemize}
    \item Peloton
    \begin{itemize}
        \item Full compilation of the entire query plan
        \item Relax the pipeline breakers of HyPEr to create mini-batches for operators that can be vectorized
        \item Use software pre-fetching to hide memory stalls
    \end{itemize}
\end{itemize}

\section{Conclusion}
\begin{itemize}
    \item Query compilation makes a difference but is non-trivial to implement
    \item The 2016 version of MemSQL is the best query compilation implementation out there
\end{itemize}


\end{document}
