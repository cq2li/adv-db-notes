\documentclass[11pt]{article}

\newcommand{\lecturenumber}{14}
\newcommand{\lecturename}{Query Compilation}
\newcommand{\lecturedata}{2018-01-24}

\usepackage{../dbnotes}

\begin{document}

\maketitle
\thispagestyle{plain}

%% ==================================================================
%% BACKGROUND
%% ==================================================================
\section{Background}
After switching to an in-memory DBMS, the only ways to increase throughput is to reduce the number 
of instructions executed~\cite{freedman2014}:
\begin{itemize}
    \item
    To go 10$\times$ faster, the DBMS must execute 90\% fewer instructions.
    
    \item
    To go 100$\times$ faster, the DBMS must execute 99\% fewer instructions.
\end{itemize}
    
One way to achieve such a reduction in instructions is through \textbf{code specialization}. This 
means generating code (e.g., machine code and source code) that is specific to a particular task in 
the DBMS (e.g., a specific query) on the fly.

%% ==================================================================
%% QUERY PROCESSING
%% ==================================================================
\section{Query Processing Recap}
There are three ways for a DBMS to execute a query plan:
\begin{itemize}
    \item \textbf{Tuple-at-a-time}:
    Each operator calls \textbf{next} on their child to get the next tuple to process. 
    Also known as the \textit{Volcano}~\cite{graefe1994} iterator model. \\
    Example: This is the approach used by most DBMSs.
    
    \item \textbf{Operator-at-a-time}:
    Each operator materializes their entire output for their parent operator.
    This approach is ideal for in-memory OLTP engines because it reduces the number of function 
    calls and the number of tuples emitted per operator is small. \\
    Example: \dbSys{H-Store}/\dbSys{VoltDB}, \dbSys{MonetDB}.
    
    \item \textbf{Vector-at-a-time}:
    Each operator calls \textbf{next} on their child to get the next \textbf{batch} of data to 
    process. \\
    Example: \dbSys{VectorWise}~\cite{bonc2005}, \dbSys{Peloton}~\cite{menon2017}.
\end{itemize}
    
Predicate Interpretation:
\begin{itemize}
    \item
    DBMS evaluates predicates using an expression tree.
    
    \item
    Expression trees are expensive to interpret when a query accesses a lot of tuples.
\end{itemize}

%% ==================================================================
%% CODE SPECIALIZATION
%% ==================================================================
\section{Code Specialization}
Code specialization tries to natively compile the CPU intensive entities of databases if they have a 
similar execution pattern on different inputs. The operations include:
\begin{itemize}
    \item Access methods
    \item Stored procedure
    \item Operator execution
    \item Predicate evaluation
    \item Logging operations
\end{itemize}
    
Because relational DBMSs have schemas, code specialization has three benefits:
\begin{itemize}
    \item
    Since attribute types are known \textit{a priori}, the DBMS can convert data access function 
    calls to inline pointer casting.
    
    \item
    Since predicates are known \textit{a priori}, the DBMS can evaluate them using primitive 
    data comparisons.
    
    \item
    The DBMS can have no function calls in loops. This allows the compiler to efficiently distribute 
    data to registers and increase cache reuse.
\end{itemize}

%% ==================================================================
%% CODE GENERATION
%% ==================================================================
\section{Code Generation}
When executing a query, the DBMS first sends it to the parser to produce the abstract syntax tree  
(AST). The AST is then passed to the binder, which communicates with the system catalog to retrieve 
the annotated AST. The Annotated AST is then translated to physical plan by the optimizer. In the 
end, the physical plan is sent to the compiler, which uses \textbf{Code Generation} approaches to 
generate native code. 

There are two approaches of code generation:
%% ----------------------------------------------------
%% Transpilation
%% ----------------------------------------------------
\subsection*{Approach \#1 -- Transpilation (Source-to-Source Compilation)}
\begin{itemize}
	\item 
	For a given query plan, transpilation generates a C/C++ program that implements the query's 
	execution, including all the predicates and type conversions.
	It then uses an off-shelf compiler (e.g., \texttt{gcc}) to convert the code into a shared 
	object, link it to the DBMS process, and invoke the exec function to execute the query.
	
	\item 
	The generated query code can invoke any other function in the DMBS.
	This allows the generated code to use all the same components as interpreted queries (e.g., 
	concurrency control, logging/checkpoints, and indexes).
	
	\item 
	The evaluation of the \dbSys{HIQUE}~\cite{krikellas2010} system shows that the DBMS incurs fewer 
	memory stalls when executing the query but the compilation time is long (i.e., 
	greater than 100--600~ms). HIQUE does not allow for full pipelining, either.
\end{itemize}

%% ----------------------------------------------------
%% JIT Compilation
%% ----------------------------------------------------
\subsection*{Approach \#2 - JIT Compilation}
JIT Compilation generates an intermediate representation (IR) of the query that can be quickly 
compiled into native code~\cite{neumann2011}.

\begin{itemize}
    \item
    JIT compilation organizes query processing in a way to keep a tuple in CPU registers for as long 
    as possible. The query plan is divided into pipelines (i.e., how far up the query tree 
    the DBMS can continue processing a tuple before needing the next tuple). This approach is 
    push-based and data-centric.

    \item
    The \dbSys{HyPer} DBMS compiles queries into native code using the LLVM 
    toolkit~\cite{lattner2004}. LLVM is a collection of modular and reusable compiler and toolchain 
    technologies. Its core component is a low-level programming language (IR) that is similar to 
    assembly.
    Like transpiilation, LLVM doesn't need to implement all of the DBMS components in IR. The LLVM 
    code can make calls to C++ code.
    

    \item
    LLVM compilation cost is low with OLTP queries, but may have major problems with OLAP workloads. 
    It grows super-linearly relative to the query size (\# of joins, predicates, and aggregations).

\end{itemize}
        
One solution to mask the compilation time is \dbSys{HyPer}'s \textbf{Adaptive Execution} 
model~\cite{kohn2018}:
\begin{enumerate}
    \item
    The model first generates the LLVM IR for the query.
    
    \item
    It then executes the IR in an interpreter while compiling the query in a background thread.
    
    \item
    After the compilation, it seamlesly replaces the interpretive execution with the compiled code.
\end{enumerate}

%% ==================================================================
%% REAL WORLD IMPLEMENTATIONS
%% ==================================================================
\section{Real World Implementations}
\begin{itemize}
    \item \dbSys{IBM System R}~\cite{chamberlin1981}
    \begin{itemize}
        \item
        \dbSys{IBM System R} used a primitive form of code generation and query compilation in 1970s.
        
        \item
        It compiled SQL statements into assembly code by selecting code templates for each 
        operator.
        
        \item
        Technique was abandoned when IBM built \dbSys{DB2} in the 1980s.
    \end{itemize}
    
    \item \dbSys{Oracle}
    \begin{itemize}
        \item
        \dbSys{Oracle} converts PL/SQL stored procedures into \texttt{Pro*C} code and then compiled 
        into native C/C++ code.
        
        \item
        They also put Oracle-specific operations (e.g., compression, vectorization, and security) 
        directly in the SPARC chips as co-processors.
    \end{itemize}
    
    \item \dbSys{Microsoft Hekaton}~\cite{freedman2014}
    \begin{itemize}
        \item
        \dbSys{Microsoft Hekaton} can compile both procedures and SQL. Non-Hekaton queries can 
        access Hekaton tables through compiled inter-operators.
        
        \item
        It generates C code from an imperative syntax tree, compiles it into DDL, and links at 
        runtime.
    \end{itemize}
    
    \item \textbf{Cloudera Impala}~\cite{kornacker2015}
    \begin{itemize}
        \item
        LLVM JIT compilation for predicate evaluation and record parsing.
        
        \item
        Optimized record parsing is important for Impala because they need to handle multiple 
        data formats stored on HDFS.
    \end{itemize}
    
    \item \dbSys{Actian Vector} (formerly \dbSys{VectorWise})~\cite{raducanu2013}
    \begin{itemize}
        \item
        \dbSys{Actian Vector} pre-compiles thousands of ``primitives'' that perform basic operations 
        on typed data.
        
        \item
        The DBMS then executes a query plan that invokes these primitives at runtime, so that 
        function calls are amortized over multiple tuples.
    \end{itemize}
    
    \item \dbSys{MemSQL}
    \begin{itemize}
        \item
        Before 2016, \dbSys{MemSQL} performs the same C/C++ code generation as 
        HIQUE~\cite{krikellas2010} and then invokes \texttt{gcc}.
        It also converts all queries into a parameterized form and caches the compiled query plan.
        
        \item 
        Since 2016, \dbSys{MemSQL} has converted a query plan into an imperative plan expressed in a 
        high-level imperative DSL, MemSQL Programming Language (MLP), which gets executed into a 
        second language of opcodes called MemSQL Bit Code (MBC). Finally the DBMS compiles the 
        opcodes into LLVM IR and then to native code
    \end{itemize}

    \item \dbSys{VitesseDB}
    \begin{itemize}
        \item 
        Query accelerator for \dbSys{Postgres}/\dbSys{Greenplum} that uses LLVM + intra-query 
		parallelism with a push-based model. It also supports JIT predicates and makes indirect 
		calls direct or inlined. 
    \end{itemize}

    \item \dbSys{Apache Spark}
    \begin{itemize}
        \item 
        \dbSys{Apache Spark} introduced in the new Tungsten engine in 2015.
        The system converts a query's WHERE clause expression trees into AST, and then compiles 
        these ASTs to generate JVM bytecode, which is then executed natively
    \end{itemize}

    \item \dbSys{Peloton}~\cite{menon2017}
    \begin{itemize}
        \item 
        \dbSys{Peloton} suppports full compilation of the entire query plan.
        It relaxes the pipeline breakers of \dbSys{HyPer} to create mini-batches for operators that 
        can be vectorized and uses software pre-fetching to hide memory stalls
    \end{itemize}
\end{itemize}


% ==================================================================
% BIBLIOGRAPHY
% ==================================================================
\newpage
\bibliographystyle{abbrvnat}
\bibliography{14-compilation}



\end{document}
