\documentclass[11pt]{article}

\newcommand{\lecturenumber}{18}
\newcommand{\lecturename}{Parallel Join Algorithms (Sorting)}
\newcommand{\lecturedata}{2020-03-30}

\usepackage{../dbnotes}

\begin{document}

\maketitle
\thispagestyle{plain}

%% ==================================================================
%% Background
%% ==================================================================
\section{Background}
The \textbf{Parallel Join Algorithms} perform a join between two relations on multiple threads simultaneously to speed up operations. The two mainstream approaches today are \textbf{Hash Join} and \textbf{Sort-Merge Join}.

%% ----------------------------------------------------
%% Sort-Merge Join 
%% ----------------------------------------------------
\subsection*{Sort-Merge Join (R $\bowtie$ S)}
The Sort-Merge Join has two phases:
\begin{itemize}
	\item \textbf{Phase \#1: Sort}:
	Sort the tuples of \textbf{R} and \textbf{S} based on the join key.
	
	\item \textbf{Phase \#2: Merge}:
	Scan the sorted relations and compare tuples.
	The outer relation \textbf{R} only needs to be scanned once.
\end{itemize}

%% ==================================================================
%% Parallel Sort-Merge Join
%% ==================================================================
\section{Parallel Sort-Merge Joins}
In Parallel Sort-Merge Joins, sorting is the most expensive part. To optimize it, the DBMS should use hardware correctly to speed up the join algorithm as much as possible. It should utilize as many CPU cores as possible, be mindful of NUMA boundaries, and use SIMD instructions where applicable~\cite{Balkesen2013}.

The Parallel Sort-Merge Join can be divided into three phases:
\begin{itemize}
	\item \textbf{Phase \#1: Partitioning (optional)}:
	Partition \textbf{R} and assign them to workers / cores.
	
	\item \textbf{Phase \#2: Build}:
	Sort the tuples of \textbf{R} and \textbf{S} based on the join key.
	
	\item \textbf{Phase \#3: Probe}:
	Scan the sorted relations and compare tuples.
	The outer relation \textbf{R} only needs to be scanned once.
\end{itemize}

%% ----------------------------------------------------
%% Partitioning Phase
%% ----------------------------------------------------
\subsection*{Partition Phase}
There are two general approaches for paritioning:
\begin{itemize}
	\item \textbf{Implicit Partitioning}: 
	The data was partitioned on the join key when it was loaded into the database.
	No extra pass over the data is needed.
	
	\item \textbf{Explicit Partitioning}: 
	Divide only the outer relation and redistribute among the different CPU cores.
	Can use the same radix partitioning approach we talked about last time.

\end{itemize}

%% ----------------------------------------------------
%% Sort Phase
%% ----------------------------------------------------
\subsection*{Sort Phase}
Create runs of sorted chunks of tuples for both input relations. It used to be that Quicksort was good enough and it usually still is. We can explore other methods that try to take advantage of NUMA and parallel architectures.

\textbf{Cache-Conscious Sorting}\\
There are three levels for the Cache-Conscious Sorting~\cite{Kim2009}:
\begin{itemize}
	\item \textbf{Level \#1: In-Register Sorting}: Sort runs that fit into CPU registers.
	
	\textbf{Sorting Networks}: Abstract model for sorting keys. Fixed wiring “paths” for lists with the same number of elements. Efficient to execute on modern CPUs because of limited data dependencies and no branches.
	
	\item \textbf{Level \#2: In-Cache Sorting}: Merge Level \#1 output into runs that fit into CPU caches. Repeat until sorted runs are half cache size.
	
	\textbf{Bitonic Merge Network}: Like a Sorting Network but it can merge two locally-sorted lists into a globally-sorted list~\cite{Chhugani2008}. Can expand network to merge progressively larger lists up to half LLC size. Intel’s Measurements: 2.25 to 3.5 times speed-up over SISD implementation.
	
	
	\item \textbf{Level \#3: Out-of-Cache Sorting}: Used when the runs of Level \#2 exceed the size of caches.
	
	\textbf{Multi-Way Merging}: Use the Bitonic Merge Networks but split the process up into tasks. Still one worker thread per core. Link together tasks with a cache-sized FIFO queue. A task blocks when either its input queue is empty, or its output queue is full. Requires more CPU instructions but brings bandwidth and compute into balance.
\end{itemize}

\textbf{In-Place SuperScalar Samplesort}\\
Recursively partition the table by sampling keys to determine partition boundaries~\cite{Axtmann2017}. It copies data into output buffers during the partitioning phases. But when a buffer gets full, it writes it back into portions of the input array already distributed instead of allocating a new buffer.


%% ----------------------------------------------------
%% Merge Phase
%% ----------------------------------------------------
\subsection*{Merge Phase}
Iterate through the outer table and inner table in lockstep and compare join keys. May need to backtrack if there are duplicates.Can be done in parallel at the different cores without synchronization if there are separate output buffers.


%% ==================================================================
%% Sort-Merge Join Variants
%% ==================================================================
\section{Sort-Merge Join Variants}
There are several variants of Sort-Merge Join~\cite{Balkesen2013}.

%% ----------------------------------------------------
%% Multi-Way Sort-Merge (M-WAY)
%% ----------------------------------------------------
\subsection*{Multi-Way Sort-Merge (M-WAY)}
\textbf{Outer Table}: Each core sorts in parallel on local data (levels \#1/\#2). Redistribute sorted runs across cores using the multi-way merge(level \#3). \\
\textbf{Inner Table}: Same as outer table.

Merge phase is between matching pairs of chunks of outer/inner tables at each core.

%% ----------------------------------------------------
%% Multi-Pass Sort-Merge (M-PASS)
%% ----------------------------------------------------
\subsection*{Multi-Pass Sort-Merge (M-PASS)}
\textbf{Outer Table}: Same level \#1/\#2 sorting as Multi-Way. But instead of redistributing, it uses a multi-pass naïve merge on sorted runs. \\
\textbf{Inner Table}: Same as outer table.

Merge phase is between matching pairs of chunks of outer table and inner table.

%% ----------------------------------------------------
%% Massively Parallel Sort-Merge (MPSM)
%% ----------------------------------------------------
\subsection*{Massively Parallel Sort-Merge (MPSM)}
\textbf{Outer Table}: Range-partition outer table and redistribute to cores. Each core sorts in parallel on their partitions. \\
\textbf{Inner Table}: Not redistributed like outer table. Each core sorts its local data.

Merge phase is between entire sorted run of outer table and a segment of inner table.


% ==================================================================
% BIBLIOGRAPHY
% ==================================================================
\newpage
\bibliographystyle{abbrvnat}
\bibliography{18-parallel2}



\end{document}
