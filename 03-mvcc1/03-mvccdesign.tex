\documentclass[11pt]{article}

\newcommand{\lecturenumber}{03}
\newcommand{\lecturename}{Multi-Version Concurrency Control (Design Decisions)}
\newcommand{\lecturedata}{2019-01-23}
\newcommand{\rr}[1]{\textcolor{red}{#1}}

\usepackage{../dbnotes}

\begin{document}

\maketitle
\thispagestyle{plain}

%% ==================================================================
%% MULTI-VERSION CONCURRENCY CONTROL
%% ==================================================================
\section{Multi-version Concurrency Control (MVCC)}
Originally proposed in 1978 MIT dissertation ~\cite{reed1978naming}.

MVCC is currently the best approach for supporting transactions in mixed workloads.
The DBMS maintains multiple \textbf{physical} versions of an object of a single 
\textbf{logical} object in the database. 
When a transaction writes to an object, the DBMS, creates a new version of that object.
When a transaction reads an object, it reads the newest version that existed when a 
transaction started.
    
\textbf{Main Benefits}
\begin{itemize}
    \item Writes do not block readers, \rr{unlike 2PL which acquires exclusive writer locks.}
    \item Read-only transactions can read a consistent snapshot without acquiring locks.
    \item Easily support time-travel queries.
    \item \rr{Snapshot Isolation is guaranteed for MVCC implementations. Extra work is required for Serializable Isolation.}
\end{itemize}

MVCC is more than just a ``concurrency control protocol''. It completely affects how the 
DBMS manages transactions and the database. There are four key design decisions:~\cite{p781-wu}
\begin{itemize}
    \item Concurrency Control Protocol
    \item Version Storage
    \item Garbage Collection
    \item Index Management
    \item Transaction Id Wraparound
\end{itemize}
% \item Tuple Header Format
% \begin{itemize}
%     \item Txn-ID: Unique Txn Identifier
%     \item Begin/End Timestamp: Version lifetime
%     \item Pointer: Points to next or previous tuple in version chain
%     \item Additional Meta-Data
% \end{itemize}

%% ==================================================================
%% CONCURRENCY CONTROL PROTOCOL
%% ==================================================================
\section{Concurrency Control Protocol}
The DBMS is able to use all of the same concurrency control protocols \rr{(Timestamp Ordering, OCC, 2PL)} under MVCC.
\rr{\subsection*{Data Tuple Structure}}

\rr{Unlike Disk-based 2PL that needs store metadata like locks in separate data structures, in MVCC we can store the metadata with data tuple itself. Typical metadata for a tuple includes:
\begin{itemize}
    \item Unique Transaction Identifier. This is usually a timestamp.
    \item A start/end range that specifies Version Liftime. DBMS uses this to determine for a transaction, whether this paticular physical version of the tuple exists in our consistent snapshot, based on our current timestamp.
    \item A pointer to next/previous tuple.
\end{itemize}}

\subsection*{Timestamp Ordering (MV-TO):}
\begin{itemize}
    \item
    Use a \texttt{read-ts} field in the header to keep track of the timestamp of the last 
    transaction that read it.
    
    \item
    For reads, a transaction is allowed to read version if the lock is unset and its $T_id$ is between 
    \texttt{begin-ts} and \texttt{end-ts}. \rr{Latches are not required for read operations.}
    
    \item
    For writes, transaction creates a new version if no other transaction holds lock and 
    $T_id$ is greater than \texttt{read-ts}. \rr{The write operation performs CAS on the \texttt{txn-id} that provides a latch on this data tuple. After creating a new version, it updates the \texttt{end-ts} field with transaction timestamp.}
\end{itemize}
\rr{\subsection*{2 Phase-Locking (MV-2PL)}
\begin{itemize}
    \item Use a \texttt{read-cnt} field in the header as a share lock, keeping track of the number of transactions holding this lock.
    \item Use \texttt{txn-id} and \texttt{read-cnt} together as exclusive lock.
    \item For reads, a transaction is allowed to hold the share lock if \texttt{txn-id} is zero. It then performs a CAS on \texttt{read-cnt}, incrementing it by one.
    \item For writes, a transaction is allowed to hold the exclusive lock if both \texttt{txn-id} and \texttt{read-cnt} are zero.
    \item After commit, \texttt{read-cnt} and \texttt{txn-id} are reset to zero.
    \item This design is good for deadlock prevention, but needs extra global data structures for deadlock detection.
\end{itemize}}

%% ----------------------------------------------------
%% Transaction Id Wraparound
%% ----------------------------------------------------
\subsection*{Transaction Id Wraparound}
If the DBMS reaches the max value for its timestamps, it will have to wrap around and start at zero. This will make all previous versions be in the ``future'' from new transactions.

\textbf{Postgres \texttt{Txn-ID} Wraparound}
\begin{itemize}
    \item
    Stop accepting new commands when the system gets close to the max transaction id.
        
    \item
    Set a flag in each tuple header that says that it is ``frozen'' in the past. Any new 
    transaction id will always be newer than a frozen version.
        
    \item
    Runs the vacuum before the system gets close to this upper limit.
\end{itemize}

%% ==================================================================
%% VERSION STORAGE
%% ==================================================================
\section{Version Storage}
The DBMS uses the tuple's pointer field to create a latch-free \textbf{version chain} per logical 
tuple. This allows the DBMS to find the version that is visible to a particular transaction at 
runtime. Indexes always point to ``head'' of the chain.

Thread store versions in ``local'' memory regions to avoid contention on centralized data 
structures. Different storage schemes determine where/what to store for each version.

For non-inline attributes, the DBMS can reuse pointers to variable-length pool for values that do 
not change between versions. This requires reference counters to know when it is safe to free 
memory. This optimization also makes it more difficult to relocate memory from the variable-length 
pool.
    
%% ----------------------------------------------------
%% Append-Only Storage
%% ----------------------------------------------------
\subsection*{Append-Only Storage}
    \begin{itemize}
        \item
        All of the physical versions of a logical tuple are stored in the same table space 
        (table heap).
        
        \item
        On update, append new tuple to same table heap in an empty slot \rr{and update pointer. There are two ways of connecting pointers:}
        \begin{itemize}
            \item \textbf{Oldest-to-Newest (O2N):}
        Append new version to end of chain, traverse entire chain on lookup.
        
        \item \textbf{Newest-to-Oldest (N2O):}
        Have to update index pointers for every new version, but do not have to traverse chain on 
        look ups.
        \end{itemize}
\end{itemize}

%% ----------------------------------------------------
%% Time-Travel Storage
%% ----------------------------------------------------
\subsection*{Time-Travel Storage}
\begin{itemize}
    \item \rr{The main table keeps the latest version of tuples.}
    \item
    On every update, copy current version to the time-travel table, and update pointer of current version.
    \item
    Overwrite master version in main table, and update pointer.
    \item
    \rr{Garbage collection is fast since we can just delete the time table.}
    \item \rr{Sequential scans are easy since we don't need to care about what versions we are looking at.}
\end{itemize}

%% ----------------------------------------------------
%% Delta Storage
%% ----------------------------------------------------
\subsection*{Delta Storage}
\begin{itemize}
    \item \rr{The main table keeps the latest version of tuples.}
    \item
    On every update, copy only the values that were modified into the delta storage and 
    overwrite the master version.
    
    \item
    Transaction can recreate old versions by applying the delta in reverse order.
    \item \rr{Garbage collection is fast since we can just delete our delta table.
    \item Good for conserving space as we do not have to copy an entire tuple, but at the cost of slower reconstruction speed for reading previous versions.
    \item Adapted in most DBMS (Oracle, MySQL).}
\end{itemize}
\rr{\subsection*{Non-inline Attributes}
Variable-length data can be stored in separate space and be referenced by a pointer in the data tuple. Direct duplication of these data is wasteful, so we can reuse pointers to variable-length pool for values that do not change between versions. One option is to use reference counters to know when it is safe to free from memory. However, as a result we would not be able to relocate memory easily. In practice, \textit{dictionary compression} solves this problem automatically.}

% TODO: Add discussion of non-inline attributes

%% ==================================================================
%% GARBAGE COLLECTION
%% ==================================================================
\section{Garbage Collection}
The DBMS needs to remove \textbf{reclaimable} physical versions from the database over 
time. A version is reclaimable if (1) no active transaction in the DBMS can see that version or 
(2) the version was created by an aborted transaction.

%% ----------------------------------------------------
%% Tuple Level
%% ----------------------------------------------------
\subsection*{Tuple Level}
\begin{itemize}
    \item
    Find old versions by examining tuples directly.
    
    \item \textbf{Background Vacuuming:}
    Separate threads periodically scan the table and look for 
    reclaimable versions. Works with any version storage technique. \rr{To avoid repeatedly scanning through unmodified data, we can use a \textit{Dirty Block BitMap} to keep track of what blocks of data have been modified since the last scan.}
    
    \item \textbf{Cooperative Cleaning:}
    Worker threads identify reclaimable versions as they 
    traverse version change. Only works with O2N version chains. \rr{A problem with this is that if there are no lookups for some data tuples, they will become "dusty corners" and will not be checked for garbage collections.}
\end{itemize}

%% ----------------------------------------------------
%% Transaction Level
%% ----------------------------------------------------
\subsection*{Transaction Level}
\begin{itemize}
    \item
    Transactions keep track of their old version so the DBMS does not have to scan tuples 
    to determine visibility.
    
    \item
    The DBMS determines when all versions created by a finishing transaction are no 
    longer visible.
    
    \item
    May still maintain multiple threads to reclaim the memory fast enough for the workload.
\end{itemize}

%% ==================================================================
%% INDEX MANAGEMENT
%% ==================================================================
\section{Index Management}
How often the DBMS updates index depends on whether system creates new versions when a tuple is updated. [Add more introduction, compare single vs multi-versioning]

%% ----------------------------------------------------
%% Primary Key
%% ----------------------------------------------------
\subsection*{Primary Key}
Primary key indexes always point to the version chain head.
If a transaction updates a primary key attribute(s), then this is treated as a \texttt{DELETE} 
followed by an \texttt{INSERT}.

%% ----------------------------------------------------
%% Secondary Indexes
%% ----------------------------------------------------
\subsection*{Secondary Indexes}
\textit{Add introduction paragraph}        

\textbf{Approach \#1: Physical Address}
\begin{itemize}
    \item \rr{Use physical address to the version chain head.} 
    \item \rr{If we have a lot of Secondary Indexes, updates would become expensive since they all point to the same location.}
\end{itemize}

\textbf{Approach \#2: Logical Pointer}
\begin{itemize}
    \item Primary Key: 
    \begin{itemize}
    \item \rr{Store Primary Key as value for a Secondary Index, which will then redirect to the physical address.}
    \item \rr{Bad if Primary Key is too large.}
    \end{itemize}
    \item Tuple ID:
    \begin{itemize}
    \item Use a fixed identifier per tuple that \textbf{does not change}.
    \item Requires an extra indirection layer. \rr{This could be a hash table that maps Tuple IDs to physical addresses.}
\end{itemize}
\end{itemize}

% ==================================================================
% BIBLIOGRAPHY
% ==================================================================
\newpage
\bibliographystyle{abbrvnat}
\bibliography{03-mvccdesign}

\end{document}
